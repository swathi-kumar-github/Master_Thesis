% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{r1}
\BIBentryALTinterwordspacing
Z.~Yang, F.~Zhan, K.~Liu, M.~Xu and S.~Lu, ``Ai-generated images as data
  source: The dawn of synthetic era,'' 2023. [Online]. Available:
  \url{https://arxiv.org/abs/2310.01830}
\BIBentrySTDinterwordspacing

\bibitem{r2}
K.~El~Emam, L.~Mosquera and R.~Hoptroff, \emph{Practical synthetic data
  generation: balancing privacy and the broad availability of data}.\hskip 1em
  plus 0.5em minus 0.4em\relax O'Reilly Media, 2020.

\bibitem{tu2007learning}
Z.~Tu, ``Learning generative models via discriminative approaches,'' in
  \emph{2007 IEEE Conference on Computer Vision and Pattern Recognition}.\hskip
  1em plus 0.5em minus 0.4em\relax IEEE, 2007, pp. 1--8.

\bibitem{Nanda:2024}
N.~Arun, ``Generative vs discriminative models: Differences & use cases,''
  \url{https://www.datacamp.com/blog/generative-vs-discriminative-models}, Sep.
  2020.

\bibitem{Karen:2020}
K.~Walker, ``Synthetic data: Unlocking the power of data and skills for machine
  learning,''
  \url{https://dataingovernment.blog.gov.uk/2020/08/20/synthetic-data-unlocking-the-power-of-data-and-skills-for-machine-learning/},
  2020.

\bibitem{goodfellow2014generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville and Y.~Bengio, ``Generative adversarial nets,'' \emph{Advances
  in neural information processing systems}, vol.~27, 2014.

\bibitem{wang2017generative}
K.~Wang, C.~Gou, Y.~Duan, Y.~Lin, X.~Zheng and F.-Y. Wang, ``Generative
  adversarial networks: introduction and outlook,'' \emph{IEEE/CAA Journal of
  Automatica Sinica}, vol.~4, no.~4, pp. 588--598, 2017.

\bibitem{radford2015unsupervised}
A.~Radford, ``Unsupervised representation learning with deep convolutional
  generative adversarial networks,'' \emph{arXiv preprint arXiv:1511.06434},
  2015.

\bibitem{arjovsky2017wasserstein}
M.~Arjovsky, S.~Chintala and L.~Bottou, ``Wasserstein generative adversarial
  networks,'' in \emph{International conference on machine learning}.\hskip 1em
  plus 0.5em minus 0.4em\relax PMLR, 2017, pp. 214--223.

\bibitem{mao2017least}
X.~Mao, Q.~Li, H.~Xie, R.~Y. Lau, Z.~Wang and S.~Paul~Smolley, ``Least squares
  generative adversarial networks,'' in \emph{Proceedings of the IEEE
  international conference on computer vision}, 2017, pp. 2794--2802.

\bibitem{karras2017progressive}
T.~Karras, ``Progressive growing of gans for improved quality, stability, and
  variation,'' \emph{arXiv preprint arXiv:1710.10196}, 2017.

\bibitem{unknown}
F.~Eckerli and J.~Osterrieder, ``Generative adversarial networks in finance: an
  overview,'' 06 2021.

\bibitem{isola2017image}
P.~Isola, J.-Y. Zhu, T.~Zhou and A.~A. Efros, ``Image-to-image translation with
  conditional adversarial networks,'' in \emph{Proceedings of the IEEE
  conference on computer vision and pattern recognition}, 2017, pp. 1125--1134.

\bibitem{sangkloy2017scribbler}
P.~Sangkloy, J.~Lu, C.~Fang, F.~Yu and J.~Hays, ``Scribbler: Controlling deep
  image synthesis with sketch and color,'' in \emph{Proceedings of the IEEE
  conference on computer vision and pattern recognition}, 2017, pp. 5400--5409.

\bibitem{zhu2017unpaired}
J.-Y. Zhu, T.~Park, P.~Isola and A.~A. Efros, ``Unpaired image-to-image
  translation using cycle-consistent adversarial networks,'' in
  \emph{Proceedings of the IEEE international conference on computer vision},
  2017, pp. 2223--2232.

\bibitem{article}
E.~Baykal~Kablan, ``Regional realness-aware generative adversarial networks for
  stain normalization,'' \emph{Neural Computing and Applications}, vol.~35, 05
  2023.

\bibitem{VAE}
D.~P. Kingma, M.~Welling \emph{et~al.}, ``An introduction to variational
  autoencoders,'' \emph{Foundations and Trends{\textregistered} in Machine
  Learning}, vol.~12, no.~4, pp. 307--392, 2019.

\bibitem{diffusion1}
J.~Sohl-Dickstein, E.~Weiss, N.~Maheswaranathan and S.~Ganguli, ``Deep
  unsupervised learning using nonequilibrium thermodynamics,'' in
  \emph{International conference on machine learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2015, pp. 2256--2265.

\bibitem{diffusion2}
J.~Ho, A.~Jain and P.~Abbeel, ``Denoising diffusion probabilistic models,''
  \emph{Advances in neural information processing systems}, vol.~33, pp.
  6840--6851, 2020.

\bibitem{DALL_E}
A.~Ramesh, M.~Pavlov, G.~Goh, S.~Gray, C.~Voss, A.~Radford, M.~Chen and
  I.~Sutskever, ``Zero-shot text-to-image generation,'' in \emph{International
  conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax Pmlr,
  2021, pp. 8821--8831.

\bibitem{CLIP}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark \emph{et~al.}, ``Learning transferable visual
  models from natural language supervision,'' in \emph{International conference
  on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2021, pp.
  8748--8763.

\bibitem{ViT}
D.~Alexey, ``An image is worth 16x16 words: Transformers for image recognition
  at scale,'' \emph{arXiv preprint arXiv: 2010.11929}, 2020.

\bibitem{Improved_denoising_diffusion}
A.~Q. Nichol and P.~Dhariwal, ``Improved denoising diffusion probabilistic
  models,'' in \emph{International conference on machine learning}.\hskip 1em
  plus 0.5em minus 0.4em\relax PMLR, 2021, pp. 8162--8171.

\bibitem{ho2022classifier}
J.~Ho and T.~Salimans, ``Classifier-free diffusion guidance,'' \emph{arXiv
  preprint arXiv:2207.12598}, 2022.

\bibitem{nichol2021glide}
A.~Nichol, P.~Dhariwal, A.~Ramesh, P.~Shyam, P.~Mishkin, B.~McGrew,
  I.~Sutskever and M.~Chen, ``Glide: Towards photorealistic image generation
  and editing with text-guided diffusion models,'' \emph{arXiv preprint
  arXiv:2112.10741}, 2021.

\bibitem{Latent_Diffusion}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser and B.~Ommer, ``High-resolution
  image synthesis with latent diffusion models,'' in \emph{Proceedings of the
  IEEE/CVF conference on computer vision and pattern recognition}, 2022, pp.
  10\,684--10\,695.

\bibitem{openai2022_dalle2}
\BIBentryALTinterwordspacing
OpenAI, ``DallÂ·e 2: A new era of image generation,'' 2022. [Online].
  Available: \url{https://openai.com/dall-e-2/}
\BIBentrySTDinterwordspacing

\bibitem{ramesh2022hierarchical}
A.~Ramesh, P.~Dhariwal, A.~Nichol, C.~Chu and M.~Chen, ``Hierarchical
  text-conditional image generation with clip latents,'' \emph{arXiv preprint
  arXiv:2204.06125}, vol.~1, no.~2, p.~3, 2022.

\bibitem{IMAGEN}
C.~Saharia, W.~Chan, S.~Saxena, L.~Li, J.~Whang, E.~L. Denton, K.~Ghasemipour,
  R.~Gontijo~Lopes, B.~Karagol~Ayan, T.~Salimans \emph{et~al.},
  ``Photorealistic text-to-image diffusion models with deep language
  understanding,'' \emph{Advances in neural information processing systems},
  vol.~35, pp. 36\,479--36\,494, 2022.

\bibitem{midjourney2022}
\BIBentryALTinterwordspacing
MidJourney, ``Midjourney: Surrealistic text-to-image generation,'' 2022,
  accessed: 2022-09-15. [Online]. Available: \url{https://www.midjourney.com/}
\BIBentrySTDinterwordspacing

\bibitem{stable_diffusion}
A.~Borji, ``Generated faces in the wild: Quantitative comparison of stable
  diffusion, midjourney and dall-e 2,'' \emph{arXiv preprint arXiv:2210.00586},
  2022.

\bibitem{Khandelwal:2021}
K.~Renu, ``Anomaly detection using autoencoders,''
  \url{https://towardsdatascience.com/anomaly-detection-using-autoencoders-5b032178a1ea},
  Jan. 2021.

\bibitem{tensorflow_imagedatagenerator}
\BIBentryALTinterwordspacing
{TensorFlow}, ``Imagedatagenerator.'' [Online]. Available:
  \url{https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator}
\BIBentrySTDinterwordspacing

\bibitem{ORB}
E.~Rublee, V.~Rabaud, K.~Konolige and G.~Bradski, ``Orb: An efficient
  alternative to sift or surf,'' in \emph{2011 International conference on
  computer vision}.\hskip 1em plus 0.5em minus 0.4em\relax Ieee, 2011, pp.
  2564--2571.

\bibitem{VGG16}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{modecollapse}
H.~Thanh-Tung and T.~Tran, ``Catastrophic forgetting and mode collapse in
  gans,'' in \emph{2020 international joint conference on neural networks
  (ijcnn)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2020, pp. 1--10.

\end{thebibliography}
