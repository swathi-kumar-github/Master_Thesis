% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{r1}
\BIBentryALTinterwordspacing
Z.~Yang, F.~Zhan, K.~Liu, M.~Xu and S.~Lu, ``Ai-generated images as data
  source: The dawn of synthetic era,'' 2023. [Online]. Available:
  \url{https://arxiv.org/abs/2310.01830}
\BIBentrySTDinterwordspacing

\bibitem{r2}
K.~El~Emam, L.~Mosquera and R.~Hoptroff, \emph{Practical synthetic data
  generation: balancing privacy and the broad availability of data}.\hskip 1em
  plus 0.5em minus 0.4em\relax O'Reilly Media, 2020.

\bibitem{wuttke2024}
\BIBentryALTinterwordspacing
L.~Wuttke, ``Machine learning vs. deep learning: What’s the difference?''
  April 2024. [Online]. Available:
  \url{https://datasolut.com/machine-learning-vs-deep-learning/}
\BIBentrySTDinterwordspacing

\bibitem{hardesty2017explained}
L.~Hardesty, ``Explained: neural networks,'' \emph{MIT News}, vol.~14, 2017.

\bibitem{luhaniwal2019}
\BIBentryALTinterwordspacing
V.~Luhaniwal, ``Forward propagation in neural networks — simplified (math and
  code version),'' May 2019. [Online]. Available:
  \url{https://towardsdatascience.com/forward-propagation-in-neural-networks-simplified-math-and-code-version-bbcfef6f9250}
\BIBentrySTDinterwordspacing

\bibitem{rumelhart1986learning}
D.~E. Rumelhart, G.~E. Hinton and R.~J. Williams, ``Learning representations by
  back-propagating errors,'' \emph{nature}, vol. 323, no. 6088, pp. 533--536,
  1986.

\bibitem{tu2007learning}
Z.~Tu, ``Learning generative models via discriminative approaches,'' in
  \emph{2007 IEEE Conference on Computer Vision and Pattern Recognition}.\hskip
  1em plus 0.5em minus 0.4em\relax IEEE, 2007, pp. 1--8.

\bibitem{deng2016deep}
L.~Deng and N.~Jaitly, ``Deep discriminative and generative models for speech
  pattern recognition,'' in \emph{Handbook of pattern recognition and computer
  vision}.\hskip 1em plus 0.5em minus 0.4em\relax World Scientific, 2016, pp.
  27--52.

\bibitem{wikipedia2024}
{Wikipedia contributors}, ``Discriminative model --- wikipedia{,} the free
  encyclopedia,'' \url{https://en.wikipedia.org/wiki/Discriminative_model},
  last edited: 4 October 2024.

\bibitem{Nanda:2024}
N.~Arun, ``Generative vs discriminative models: Differences & use cases,''
  \url{https://www.datacamp.com/blog/generative-vs-discriminative-models}, Sep.
  2020.

\bibitem{zheng2023toward}
C.~Zheng, G.~Wu and C.~Li, ``Toward understanding generative data
  augmentation,'' \emph{Advances in neural information processing systems},
  vol.~36, pp. 54\,046--54\,060, 2023.

\bibitem{ng2001discriminative}
A.~Ng and M.~Jordan, ``On discriminative vs. generative classifiers: A
  comparison of logistic regression and naive bayes,'' \emph{Advances in neural
  information processing systems}, vol.~14, 2001.

\bibitem{raghunathan2021synthetic}
T.~E. Raghunathan, ``Synthetic data,'' \emph{Annual review of statistics and
  its application}, vol.~8, no.~1, pp. 129--140, 2021.

\bibitem{Karen:2020}
K.~Walker, ``Synthetic data: Unlocking the power of data and skills for machine
  learning,''
  \url{https://dataingovernment.blog.gov.uk/2020/08/20/synthetic-data-unlocking-the-power-of-data-and-skills-for-machine-learning/},
  2020.

\bibitem{anderson2022synthetic}
J.~W. Anderson, M.~Ziolkowski, K.~Kennedy and A.~W. Apon, ``Synthetic image
  data for deep learning,'' \emph{arXiv preprint arXiv:2212.06232}, 2022.

\bibitem{schonfeld2022improving}
E.~Sch{\"o}nfeld, ``Improving quality and controllability in gan-based image
  synthesis,'' 2022.

\bibitem{wang2023diffusion}
B.~Wang and J.~J. Vastola, ``Diffusion models generate images like painters: an
  analytical theory of outline first, details later,'' \emph{arXiv preprint
  arXiv:2303.02490}, 2023.

\bibitem{cai2019multi}
L.~Cai, H.~Gao and S.~Ji, ``Multi-stage variational auto-encoders for
  coarse-to-fine image generation,'' in \emph{Proceedings of the 2019 SIAM
  international conference on data mining}.\hskip 1em plus 0.5em minus
  0.4em\relax SIAM, 2019, pp. 630--638.

\bibitem{goodfellow2014generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville and Y.~Bengio, ``Generative adversarial nets,'' \emph{Advances
  in neural information processing systems}, vol.~27, 2014.

\bibitem{wang2017generative}
K.~Wang, C.~Gou, Y.~Duan, Y.~Lin, X.~Zheng and F.-Y. Wang, ``Generative
  adversarial networks: introduction and outlook,'' \emph{IEEE/CAA Journal of
  Automatica Sinica}, vol.~4, no.~4, pp. 588--598, 2017.

\bibitem{lee2022generator}
G.~Lee, H.~Kim, J.~Kim, S.~Kim, J.-W. Ha and Y.~Choi, ``Generator knows what
  discriminator should learn in unconditional gans,'' in \emph{European
  Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2022, pp. 406--422.

\bibitem{radford2015unsupervised}
A.~Radford, ``Unsupervised representation learning with deep convolutional
  generative adversarial networks,'' \emph{arXiv preprint arXiv:1511.06434},
  2015.

\bibitem{arjovsky2017wasserstein}
M.~Arjovsky, S.~Chintala and L.~Bottou, ``Wasserstein generative adversarial
  networks,'' in \emph{International conference on machine learning}.\hskip 1em
  plus 0.5em minus 0.4em\relax PMLR, 2017, pp. 214--223.

\bibitem{mao2017least}
X.~Mao, Q.~Li, H.~Xie, R.~Y. Lau, Z.~Wang and S.~Paul~Smolley, ``Least squares
  generative adversarial networks,'' in \emph{Proceedings of the IEEE
  international conference on computer vision}, 2017, pp. 2794--2802.

\bibitem{karras2017progressive}
T.~Karras, ``Progressive growing of gans for improved quality, stability, and
  variation,'' \emph{arXiv preprint arXiv:1710.10196}, 2017.

\bibitem{eckerli2106generative}
F.~Eckerli and J.~Osterrieder, ``Generative adversarial networks in finance: An
  overview. arxiv 2021,'' \emph{arXiv preprint arXiv:2106.06364}.

\bibitem{gauthier2014conditional}
J.~Gauthier, ``Conditional generative adversarial nets for convolutional face
  generation,'' \emph{Class project for Stanford CS231N: convolutional neural
  networks for visual recognition, Winter semester}, vol. 2014, no.~5, p.~2,
  2014.

\bibitem{isola2017image}
P.~Isola, J.-Y. Zhu, T.~Zhou and A.~A. Efros, ``Image-to-image translation with
  conditional adversarial networks,'' in \emph{Proceedings of the IEEE
  conference on computer vision and pattern recognition}, 2017, pp. 1125--1134.

\bibitem{sangkloy2017scribbler}
P.~Sangkloy, J.~Lu, C.~Fang, F.~Yu and J.~Hays, ``Scribbler: Controlling deep
  image synthesis with sketch and color,'' in \emph{Proceedings of the IEEE
  conference on computer vision and pattern recognition}, 2017, pp. 5400--5409.

\bibitem{zhu2017unpaired}
J.-Y. Zhu, T.~Park, P.~Isola and A.~A. Efros, ``Unpaired image-to-image
  translation using cycle-consistent adversarial networks,'' in
  \emph{Proceedings of the IEEE international conference on computer vision},
  2017, pp. 2223--2232.

\bibitem{article}
E.~Baykal~Kablan, ``Regional realness-aware generative adversarial networks for
  stain normalization,'' \emph{Neural Computing and Applications}, vol.~35, 05
  2023.

\bibitem{VAE}
D.~P. Kingma, M.~Welling \emph{et~al.}, ``An introduction to variational
  autoencoders,'' \emph{Foundations and Trends{\textregistered} in Machine
  Learning}, vol.~12, no.~4, pp. 307--392, 2019.

\bibitem{diffusion1}
J.~Sohl-Dickstein, E.~Weiss, N.~Maheswaranathan and S.~Ganguli, ``Deep
  unsupervised learning using nonequilibrium thermodynamics,'' in
  \emph{International conference on machine learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2015, pp. 2256--2265.

\bibitem{diffusion2}
J.~Ho, A.~Jain and P.~Abbeel, ``Denoising diffusion probabilistic models,''
  \emph{Advances in neural information processing systems}, vol.~33, pp.
  6840--6851, 2020.

\bibitem{yainnoware2022}
Yainnoware, ``Decoding the math behind9 diffusion models,''
  \url{https://yainnoware.blogspot.com/2022/11/decoding-math-behind-diffusion-models.html},
  November 20 2022.

\bibitem{DALL_E}
A.~Ramesh, M.~Pavlov, G.~Goh, S.~Gray, C.~Voss, A.~Radford, M.~Chen and
  I.~Sutskever, ``Zero-shot text-to-image generation,'' in \emph{International
  conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax Pmlr,
  2021, pp. 8821--8831.

\bibitem{CLIP}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark \emph{et~al.}, ``Learning transferable visual
  models from natural language supervision,'' in \emph{International conference
  on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2021, pp.
  8748--8763.

\bibitem{ViT}
D.~Alexey, ``An image is worth 16x16 words: Transformers for image recognition
  at scale,'' \emph{arXiv preprint arXiv: 2010.11929}, 2020.

\bibitem{openai2021}
OpenAI, ``Dall·e: Creating images from text,''
  \url{https://openai.com/index/dall-e/}, January 2021.

\bibitem{Improved_denoising_diffusion}
A.~Q. Nichol and P.~Dhariwal, ``Improved denoising diffusion probabilistic
  models,'' in \emph{International conference on machine learning}.\hskip 1em
  plus 0.5em minus 0.4em\relax PMLR, 2021, pp. 8162--8171.

\bibitem{ho2022classifier}
J.~Ho and T.~Salimans, ``Classifier-free diffusion guidance,'' \emph{arXiv
  preprint arXiv:2207.12598}, 2022.

\bibitem{nichol2021glide}
A.~Nichol, P.~Dhariwal, A.~Ramesh, P.~Shyam, P.~Mishkin, B.~McGrew,
  I.~Sutskever and M.~Chen, ``Glide: Towards photorealistic image generation
  and editing with text-guided diffusion models,'' \emph{arXiv preprint
  arXiv:2112.10741}, 2021.

\bibitem{Latent_Diffusion}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser and B.~Ommer, ``High-resolution
  image synthesis with latent diffusion models,'' in \emph{Proceedings of the
  IEEE/CVF conference on computer vision and pattern recognition}, 2022, pp.
  10\,684--10\,695.

\bibitem{openai2022_dalle2}
\BIBentryALTinterwordspacing
OpenAI, ``Dall·e 2: A new era of image generation,'' 2022. [Online].
  Available: \url{https://openai.com/dall-e-2/}
\BIBentrySTDinterwordspacing

\bibitem{ramesh2022hierarchical}
A.~Ramesh, P.~Dhariwal, A.~Nichol, C.~Chu and M.~Chen, ``Hierarchical
  text-conditional image generation with clip latents,'' \emph{arXiv preprint
  arXiv:2204.06125}, vol.~1, no.~2, p.~3, 2022.

\bibitem{IMAGEN}
C.~Saharia, W.~Chan, S.~Saxena, L.~Li, J.~Whang, E.~L. Denton, K.~Ghasemipour,
  R.~Gontijo~Lopes, B.~Karagol~Ayan, T.~Salimans \emph{et~al.},
  ``Photorealistic text-to-image diffusion models with deep language
  understanding,'' \emph{Advances in neural information processing systems},
  vol.~35, pp. 36\,479--36\,494, 2022.

\bibitem{midjourney2022}
\BIBentryALTinterwordspacing
MidJourney, ``Midjourney: Surrealistic text-to-image generation,'' 2022,
  accessed: 2022-09-15. [Online]. Available: \url{https://www.midjourney.com/}
\BIBentrySTDinterwordspacing

\bibitem{stable_diffusion}
A.~Borji, ``Generated faces in the wild: Quantitative comparison of stable
  diffusion, midjourney and dall-e 2,'' \emph{arXiv preprint arXiv:2210.00586},
  2022.

\bibitem{panza2023anomaly}
M.~A. Panza, M.~Pota and M.~Esposito, ``Anomaly detection methods for
  industrial applications: A comparative study,'' \emph{Electronics}, vol.~12,
  no.~18, p. 3971, 2023.

\bibitem{torabi2023practical}
H.~Torabi, S.~L. Mirtaheri and S.~Greco, ``Practical autoencoder based anomaly
  detection by using vector reconstruction error,'' \emph{Cybersecurity},
  vol.~6, no.~1, p.~1, 2023.

\bibitem{Khandelwal:2021}
K.~Renu, ``Anomaly detection using autoencoders,''
  \url{https://towardsdatascience.com/anomaly-detection-using-autoencoders-5b032178a1ea},
  Jan. 2021.

\bibitem{tensorflow_imagedatagenerator}
\BIBentryALTinterwordspacing
{TensorFlow}, ``Imagedatagenerator.'' [Online]. Available:
  \url{https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator}
\BIBentrySTDinterwordspacing

\bibitem{ORB}
E.~Rublee, V.~Rabaud, K.~Konolige and G.~Bradski, ``Orb: An efficient
  alternative to sift or surf,'' in \emph{2011 International conference on
  computer vision}.\hskip 1em plus 0.5em minus 0.4em\relax Ieee, 2011, pp.
  2564--2571.

\bibitem{VGG16}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{modecollapse}
H.~Thanh-Tung and T.~Tran, ``Catastrophic forgetting and mode collapse in
  gans,'' in \emph{2020 international joint conference on neural networks
  (ijcnn)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2020, pp. 1--10.

\end{thebibliography}
